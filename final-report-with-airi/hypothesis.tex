\section{Hypothesis}

\textbf{Hypothesis 1}: We expect the Q Learning algorithm to perform better overall than the SARSA algorithm over 10000 episodes.
%We expect both the Q-Learning and SARSA algorithms to be able to finish training after 1000 episodes and that the SARSA algorithm will have the 
%higher average rewards over 100 episodes.

\textbf{Hypothesis 2}: For SARSA, we expect exponential decay of $\epsilon$ to perform the best, as in, have the highest average reward over 10000 episodes.

\textbf{Hypothesis 3}: For Q-Learning, we will implement a softmax policy, but we expect it to not perform as well as either of the $\epsilon$ decay methods.

\textbf{Contributions): Khoi's experiments will be performed in accordance to hypothesis 2, while Airi's experiments will test hypothesis 3. Both will then contribute to hypothesis 1.